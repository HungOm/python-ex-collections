#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
A module to generate a saliency map from an RGB image

This code is based on the approach described in:
[1] X. Hou and L. Zhang (2007). Saliency Detection: A Spectral Residual
    Approach. IEEE Transactions on Computer Vision and Pattern Recognition
    (CVPR), p.1-8. doi: 10.1109/CVPR.2007.383267
"""

import cv2
import numpy as np
from matplotlib import pyplot as plt
from typing import Tuple


def _calc_channel_sal_magn(channel: np.ndarray,
                           use_numpy_fft: bool = True) -> np.ndarray:
    """
    Calculate the log-magnitude of the Fourier spectrum
    of a single-channel image. This image could be a regular grayscale
    image, or a single color channel of an RGB image.

    :param channel: single-channel input image
    :returns: log-magnitude of Fourier spectrum
    """
    # do FFT and get log-spectrum
    if use_numpy_fft:
        img_dft = np.fft.fft2(channel)
        magnitude, angle = cv2.cartToPolar(np.real(img_dft),
                                           np.imag(img_dft))
    else:
        img_dft = cv2.dft(np.float32(channel),
                          flags=cv2.DFT_COMPLEX_OUTPUT)
        magnitude, angle = cv2.cartToPolar(img_dft[:, :, 0],
                                           img_dft[:, :, 1])

    # get log amplitude
    log_ampl = np.log10(magnitude.clip(min=1e-9))

    # blur log amplitude with avg filter
    log_ampl_blur = cv2.blur(log_ampl, (3, 3))

    # residual
    residual = np.exp(log_ampl - log_ampl_blur)

    # back to cartesian frequency domain
    if use_numpy_fft:
        real_part, imag_part = cv2.polarToCart(residual, angle)
        img_combined = np.fft.ifft2(real_part + 1j * imag_part)
        magnitude, _ = cv2.cartToPolar(np.real(img_combined),
                                       np.imag(img_combined))
    else:
        img_dft[:, :, 0], img_dft[:, :, 1] = cv2.polarToCart(residual,
                                                             angle)
        img_combined = cv2.idft(img_dft)
        magnitude, _ = cv2.cartToPolar(img_combined[:, :, 0],
                                       img_combined[:, :, 1])

    return magnitude


def get_saliency_map(frame: np.ndarray,
                     small_shape: Tuple[int] = (64, 64),
                     gauss_kernel: Tuple[int] = (5, 5),
                     use_numpy_fft: bool = True) -> np.ndarray:
    """
    Returns a saliency map

    This function generates a saliency map for the image that was
    passed to the class constructor.

    :returns: grayscale saliency map
    """
    frame_small = cv2.resize(frame, small_shape)
    if len(frame.shape) == 2:
        # single channelsmall_shape[1::-1]
        sal = _calc_channel_sal_magn(frame, use_numpy_fft)
    else:
        # multiple channels: consider each channel independently
        sal = np.zeros_like(frame_small).astype(np.float32)
        for c in range(frame_small.shape[2]):
            small = frame_small[:, :, c]
            sal[:, :, c] = _calc_channel_sal_magn(small, use_numpy_fft)

        # overall saliency: channel mean
        sal = np.mean(sal, axis=2)

    # postprocess: blur, normalize, and square
    if gauss_kernel is not None:
        sal = cv2.GaussianBlur(sal, gauss_kernel, sigmaX=8, sigmaY=0)

    sal /= np.max(sal)
    return cv2.resize(sal ** 2, frame.shape[1::-1])


def get_proto_objects_map(saliency: np.ndarray, use_otsu=True) -> np.ndarray:
    """
    Generate the proto-objects map of an RGB image

    Proto-objects are saliency hot spots, generated by thresholding
    the saliency map.

    :param use_otsu: flag whether to use Otsu thresholding (True) or
                     a hardcoded threshold value (False)
    :saliency grayscale saliency map
    :returns: proto-objects map
    """
    saliency = np.uint8(saliency * 255)
    if use_otsu:
        thresh_type = cv2.THRESH_OTSU
        #  For threshold value, simply pass zero.
        thresh_value = 0
    else:
        thresh_type = cv2.THRESH_BINARY
        thresh_value = np.mean(saliency) * 3

    _, img_objects = cv2.threshold(saliency,
                                   thresh_value, 255, thresh_type)
    return img_objects


def plot_power_spectrum(frame: np.ndarray, use_numpy_fft=True) -> None:
    """Plot the power spectrum of image"""

    # convert the frame to grayscale if necessary
    if len(frame.shape) > 2:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # expand the image to an optimal size for FFT
    rows, cols = frame.shape
    nrows = cv2.getOptimalDFTSize(rows)
    ncols = cv2.getOptimalDFTSize(cols)
    frame = cv2.copyMakeBorder(frame, 0, ncols - cols, 0, nrows - rows,
                               cv2.BORDER_CONSTANT, value=0)

    # do FFT and get log-spectrum
    if use_numpy_fft:
        img_dft = np.fft.fft2(frame)
        spectrum = np.log10(np.real(np.abs(img_dft))**2)
    else:
        img_dft = cv2.dft(np.float32(frame), flags=cv2.DFT_COMPLEX_OUTPUT)
        spectrum = np.log10(img_dft[:, :, 0]**2 + img_dft[:, :, 1]**2)

    # radial average
    L = max(frame.shape)
    freqs = np.fft.fftfreq(L)[:L // 2]
    dists = np.sqrt(np.fft.fftfreq(frame.shape[0])[:, np.newaxis]**2 +
                    np.fft.fftfreq(frame.shape[1])**2)
    dcount = np.histogram(dists.ravel(), bins=freqs)[0]
    histo, bins = np.histogram(dists.ravel(), bins=freqs,
                               weights=spectrum.ravel())

    centers = (bins[:-1] + bins[1:]) / 2
    plt.plot(centers, histo / dcount)
    plt.xlabel('frequency')
    plt.ylabel('log-spectrum')
    plt.show()


def calc_magnitude_spectrum(img: np.ndarray):
    """Plot the magnitude spectrum
        This method calculates the magnitude spectrum of the image passed
        to the class constructor.
        :returns: magnitude spectrum
    """
    # convert the frame to grayscale if necessary
    if len(img.shape) > 2:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # expand the image to an optimal size for FFT
    rows, cols = img.shape
    nrows = cv2.getOptimalDFTSize(rows)
    ncols = cv2.getOptimalDFTSize(cols)
    frame = cv2.copyMakeBorder(img, 0, ncols - cols, 0, nrows - rows,
                               cv2.BORDER_CONSTANT, value=0)

    # do FFT and get log-spectrum
    img_dft = np.fft.fft2(img)
    spectrum = np.log10(np.abs(np.fft.fftshift(img_dft)))

    # return normalized
    return spectrum / np.max(spectrum)


if __name__ == '__main__':
    video = cv2.VideoCapture('soccer.avi')
    _, im = video.read()
    plt.imshow(im)
    plot_power_spectrum(im)
    plt.imshow(calc_magnitude_spectrum(cv2.imread("test.jpeg")))
